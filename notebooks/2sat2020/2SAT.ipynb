{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2SAT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqGlJOPJIsi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/satproject/neuralheuristicsforsat.git\n",
        "%cd neuralheuristicsforsat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGuEgyZaIwyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsAu7KMKIyCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -r requirements.in "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fii31dk8Iz5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-OHzvxLI1hx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch\n",
        "!pip install numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JWvuhPhI2uS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd neuralheuristicsforsat/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1-UIqe7I5Ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_example(inputs, sat):\n",
        "    example = tf.train.Example(\n",
        "        features=tf.train.Features(feature={\n",
        "            \"inputs\": tf.train.Feature(\n",
        "                float_list=tf.train.FloatList(value=list(inputs.flatten()))),\n",
        "            \"sat\": tf.train.Feature(\n",
        "                float_list=tf.train.FloatList(value=list(sat.flatten())))\n",
        "        })\n",
        "    )\n",
        "    return example.SerializeToString()\n",
        "\n",
        "\n",
        "def tf_serialize_example(sample):\n",
        "    tf_string = tf.py_func(make_example, (sample[\"inputs\"], sample[\"sat\"]), tf.string)\n",
        "    return tf.reshape(tf_string, ())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qJk1edKI9yE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import cnf_dataset\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "#Reimport a module in python while interactive\n",
        "from importlib import reload\n",
        "reload(cnf_dataset)\n",
        "reload(tf)\n",
        "\n",
        "\n",
        "def main_generate(observations, complexity, job):\n",
        "\n",
        "    random.seed(int(job))\n",
        "    print(\"Set random seed to {}\".format(int(job)))\n",
        "\n",
        "    dirname = \"sr_{}\".format(complexity)  \n",
        "    filename = \"train_{}_sr_{}.tfrecord\".format(job, complexity)\n",
        "    options = {\n",
        "        \"PROCESSOR_NUM\": 24,\n",
        "        \"CLAUSE_NUM\": 10*complexity,\n",
        "        \"VARIABLE_NUM\": complexity,\n",
        "        \"MIN_VARIABLE_NUM\": 1,\n",
        "        \"BATCH_SIZE\": 1,\n",
        "        \"CLAUSE_SIZE\": 2,\n",
        "        \"MIN_CLAUSE_NUM\": 2,\n",
        "        \"SR_GENERATOR\": False\n",
        "    }\n",
        "    n_observations = observations\n",
        "\n",
        "    if not os.path.exists(dirname):\n",
        "        os.makedirs(dirname)\n",
        "        print(\"Created directory {}\".format(dirname))\n",
        "\n",
        "    with cnf_dataset.PoolDatasetGenerator(options) as generator, \\\n",
        "            tf.python_io.TFRecordWriter(os.path.join(dirname,filename)) as writer:\n",
        "\n",
        "        for _ in tqdm(range(n_observations)):\n",
        "            sample_with_labels = generator.generate_batch(representation='cnfs')\n",
        "            print(sample_with_labels.inputs.astype(np.float32))\n",
        "            tf_sample = {\n",
        "                 \"inputs\": np.squeeze(sample_with_labels.inputs.astype(np.float32), 0),\n",
        "                 \"sat\": np.squeeze(np.asarray(sample_with_labels.sat_labels).astype(np.float32), 0)\n",
        "            }\n",
        "            \n",
        "            serialized = make_example(**tf_sample)\n",
        "            writer.write(serialized)\n",
        "main_generate(10, 10 ,12312)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVYPsy6kJEGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(x, y):\n",
        "  return sum(1 for a,b in zip(x,y) if a == b) / len(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYFlN_QCJINm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def chunkIt(seq, num):\n",
        "    avg = len(seq) / float(num)\n",
        "    out = []\n",
        "    last = 0.0\n",
        "\n",
        "    while last < len(seq):\n",
        "        out.append(list(map(int, seq[int(last):int(last + avg)])))\n",
        "        last += avg\n",
        "\n",
        "    return out\n",
        "\n",
        "def main():\n",
        "    n = 100\n",
        "    tfrecord_location = '/content/neuralheuristicsforsat/sr_100'\n",
        "    name = \"train_21021_sr_100.tfrecord\"\n",
        "    filename = os.path.join(tfrecord_location, name)\n",
        "    #filename = \"train_21021_sr_10.tfrecord\"\n",
        "\n",
        "    record_iterator = tf.python_io.tf_record_iterator(path=filename)\n",
        "    preds = []\n",
        "    targes = []\n",
        "    batch_size = n\n",
        "\n",
        "    for string_record in itertools.islice(record_iterator, 100):\n",
        "        example = tf.train.Example()\n",
        "        example.ParseFromString(string_record)\n",
        "        \n",
        "\n",
        "        M = len(example.features.feature[\"inputs\"].float_list.value)//2\n",
        "        inputs = chunkIt(example.features.feature[\"inputs\"].float_list.value, M)\n",
        "\n",
        "        preds.append(predict({'n': n, 'm': M}, inputs))\n",
        "        targes.append(int(example.features.feature[\"sat\"].float_list.value[0]))\n",
        "\n",
        "    print(accuracy(preds, targes))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}